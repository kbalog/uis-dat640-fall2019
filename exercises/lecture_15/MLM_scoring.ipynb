{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Part 2\n",
    "\n",
    "Scoring documents using the Mixture of Language Models (MLM) approach. Use two fields: title and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDEX_NAME = \"aquaint\"\n",
    "DOC_TYPE = \"doc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY_FILE = \"data/queries.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"data/mlm_default.txt\"  # output the ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document fields used for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIELDS = [\"title\", \"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field weights. You'll need to set these properly in Part 3 of the assignment. For now, you can use these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIELD_WEIGHTS = [0.2, 0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoothing: we use Jelinek-Mercer smoothing here with the following lambda parameter. (I.e., the same smoothing parameter is used for all fields.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LAMBDA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load the queries from the file\n",
    "\n",
    "See the assignment description for the format of the query file [here](https://github.com/kbalog/uis-dat630-fall2017/tree/master/assignment-1#queries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_queries(query_file):\n",
    "    queries = {}\n",
    "    with open(query_file, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            qid, query = line.strip().split(\" \", 1)\n",
    "            queries[qid] = query\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query analyzer\n",
    "\n",
    "See [indices.analyze](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.analyze)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_query(es, query):\n",
    "    tokens = es.indices.analyze(index=INDEX_NAME, body={\"text\": query})[\"tokens\"]\n",
    "    query_terms = []\n",
    "    for t in sorted(tokens, key=lambda x: x[\"position\"]):\n",
    "        query_terms.append(t[\"token\"])\n",
    "    return query_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLM scorer\n",
    "\n",
    "Documents should be scored according to **query (log)likelihood**: \n",
    "\n",
    "$\\log P(q|d) = \\sum_{t \\in q} f_{t,q} \\log P(t|\\theta_d)$, \n",
    "\n",
    "where\n",
    "  - $f_{t,q}$ is the frequency of term $t$ in the query\n",
    "  - $P(t|\\theta_d)$ is the (smoothed) document language model.\n",
    "  \n",
    "Using multiple document fields, the **document language model** is taken to be a linear combination of the (smoothed) field language models:\n",
    "\n",
    "$P(t|\\theta_d) = \\sum_i w_i P(t|\\theta_{d_i})$ ,\n",
    "\n",
    "where $w_i$ is the field weight for field $i$ (and $\\sum_i w_i = 1$).\n",
    "\n",
    "The **field language models** $P(t|\\theta_{d_i})$ are computed as follows.\n",
    "\n",
    "Using **Jelinek-Mercer smoothing**:\n",
    "\n",
    "$P(t|\\theta_{d_i}) = (1-\\lambda_i) P(t|d_i) + \\lambda_i P(t|C_i)$,\n",
    "\n",
    "where \n",
    "\n",
    "  - $\\lambda_i$ is a field-specific smoothing parameter\n",
    "  - $P(t|d_i) = \\frac{f_{t,d_i}}{|d_i|}$ is the empirical field language model (term's relative frequency in the document field). $f_{t,d_i}$ is the raw frequency of $t$ in field $i$ of $d$. $|d_i|$ is the length (number of terms) in field $i$ of $d$.\n",
    "  - $P(t|C_i) = \\frac{\\sum_{d'}f_{t,d'_i}}{\\sum_{d'}|d'_i|}$ is the collecting field language model (term's relative frequency in that field across the entire collection)\n",
    "  \n",
    "Using **Dirichlet smoothing**:\n",
    "\n",
    "$p(t|\\theta_{d_i}) = \\frac{f_{t,d_i} + \\mu_i P(t|C_i)}{|d_i| + \\mu_i}$\n",
    "\n",
    "where $\\mu_i$ is the field-specific smoothing parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection Language Model class\n",
    "\n",
    "This class is used for obtaining collection language modeling probabilities $P(t|C_i)$.\n",
    "\n",
    "The reason this class is needed is that `es.termvectors` does not return term statistics for terms that do not appear in the given document. This would cause problems in scoring documents that are partial matches (do not contain all query terms in all fields). \n",
    "\n",
    "The idea is that for each query term, we need to find a document that contains that term. Then the collection term statistics are available from that document's term vector. To make sure we find a matching document, we issue a [boolean (match)](https://www.elastic.co/guide/en/elasticsearch/reference/5.5/query-dsl-match-query.html) query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CollectionLM(object):\n",
    "    def __init__(self, es, qterms):\n",
    "        self._es = es\n",
    "        self._probs = {}\n",
    "        # computing P(t|C_i) for each field and for each query term\n",
    "        for field in FIELDS:\n",
    "            self._probs[field] = {}\n",
    "            for t in qterms:\n",
    "                self._probs[field][t] = self.__get_prob(field, t)\n",
    "        \n",
    "    def __get_prob(self, field, term):\n",
    "        # use a boolean query to find a document that contains the term\n",
    "        hits = self._es.search(index=INDEX_NAME, body={\"query\": {\"match\": {field: term}}},\n",
    "                               _source=False, size=1).get(\"hits\", {}).get(\"hits\", {})\n",
    "        doc_id = hits[0][\"_id\"] if len(hits) > 0 else None\n",
    "        if doc_id is not None:\n",
    "            # ask for global term statistics when requesting the term vector of that doc (`term_statistics=True`)\n",
    "            tv = self._es.termvectors(index=INDEX_NAME, doc_type=DOC_TYPE, id=doc_id, fields=field,\n",
    "                                      term_statistics=True)[\"term_vectors\"][field]\n",
    "            ttf = tv[\"terms\"].get(term, {}).get(\"ttf\", 0)  # total term count in the collection (in that field)\n",
    "            sum_ttf = tv[\"field_statistics\"][\"sum_ttf\"]\n",
    "            return ttf / sum_ttf\n",
    "\n",
    "        return 0  # this only happens if none of the documents contain that term\n",
    "\n",
    "    def prob(self, field, term):\n",
    "        return self._probs.get(field, {}).get(term, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_mlm(es, clm, qterms, doc_id):\n",
    "    score = 0  # log P(q|d)\n",
    "    \n",
    "    # Getting term frequency statistics for the given document field from Elasticsearch\n",
    "    # Note that global term statistics are not needed (`term_statistics=False`)\n",
    "    tv = es.termvectors(index=INDEX_NAME, doc_type=DOC_TYPE, id=doc_id, fields=FIELDS,\n",
    "                              term_statistics=False).get(\"term_vectors\", {})\n",
    "\n",
    "    # compute field lengths $|d_i|$\n",
    "    len_d_i = []  # document field length\n",
    "    for i, field in enumerate(FIELDS):\n",
    "        if field in tv: \n",
    "            len_d_i.append(sum([s[\"term_freq\"] for t, s in tv[field][\"terms\"].items()]))\n",
    "        else:  # that document field may be empty\n",
    "            len_d_i.append(0)\n",
    "        \n",
    "    # scoring the query\n",
    "    for t in qterms:\n",
    "        Pt_theta_d = 0  # P(t|\\theta_d)\n",
    "        for i, field in enumerate(FIELDS):\n",
    "            if field in tv:\n",
    "                Pt_di = tv[field][\"terms\"].get(t, {}).get(\"term_freq\", 0) / len_d_i[i]  # $P(t|d_i)$\n",
    "            else:  # that document field is empty\n",
    "                Pt_di = 0\n",
    "            Pt_Ci = clm.prob(field, t)  # $P(t|C_i)$\n",
    "            Pt_theta_di = (1 - LAMBDA) * Pt_di + LAMBDA * Pt_Ci  # $P(t|\\theta_{d_i})$ with J-M smoothing\n",
    "            Pt_theta_d += FIELD_WEIGHTS[i] * Pt_theta_di\n",
    "        score += math.log(Pt_theta_d)    \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queries = load_queries(QUERY_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get baseline ranking for [303] 'Hubble Telescope Achievements'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [307] 'New Hydroelectric Projects'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [310] 'Radio Waves and Brain Cancer'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [314] 'Marine Vegetation'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [322] 'International Art Crime'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [325] 'Cult Lifestyles'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [330] 'Iran-Iraq Cooperation'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [336] 'Black Bear Attacks'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [341] 'Airport Security'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [344] 'Abuses of E-Mail'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [345] 'Overseas Tobacco Sales'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [347] 'Wildlife Extinction'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [353] 'Antarctica exploration'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [354] 'journalist risks'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [362] 'human smuggling'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [363] 'transportation tunnel disasters'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [367] 'piracy'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [372] 'Native American casino'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [374] 'Nobel prize winners'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [375] 'hydrogen energy'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [378] 'euro opposition'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [383] 'mental illness drugs'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [389] 'illegal technology transfer'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [393] 'mercy killing'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [394] 'home schooling'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [397] 'automobile recalls'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [399] 'oceanographic vessels'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [401] 'foreign minorities, Germany'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [404] 'Ireland, peace talks'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [408] 'tropical storms'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [409] 'legal, Pan Am, 103'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [416] 'Three Gorges Project'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [419] 'recycle, automobile tires'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [426] 'law enforcement, dogs'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [427] 'UV damage, eyes'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [433] 'Greek, philosophy, stoicism'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [435] 'curbing population growth'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [436] 'railway accidents'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [439] 'inventions, scientific discoveries'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [443] 'U.S., investment, Africa'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [448] 'ship losses'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [622] 'price fixing'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [625] 'arrests bombing WTC'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [638] 'wrongful convictions'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [639] 'consumer on-line shopping'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [648] 'family leave law'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [650] 'tax evasion indicted'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [651] 'U.S. ethnic population'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [658] 'teenage pregnancy'\n",
      "Re-scoring documents using MLM\n",
      "Get baseline ranking for [689] 'family-planning aid'\n",
      "Re-scoring documents using MLM\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUT_FILE, \"w\") as fout:\n",
    "    # write header\n",
    "    fout.write(\"QueryId,DocumentId\\n\")\n",
    "    for qid, query in queries.items():\n",
    "        # get top 200 docs using BM25\n",
    "        print(\"Get baseline ranking for [%s] '%s'\" % (qid, query))\n",
    "        res = es.search(index=INDEX_NAME, q=query, df=\"content\", _source=False, size=200).get('hits', {})\n",
    "        \n",
    "        # re-score docs using MLM\n",
    "        print(\"Re-scoring documents using MLM\")\n",
    "        # get analyzed query\n",
    "        qterms = analyze_query(es, query)\n",
    "        # get collection LM \n",
    "        # (this needs to be instantiated only once per query and can be used for scoring all documents)\n",
    "        clm = CollectionLM(es, qterms)        \n",
    "        scores = {}\n",
    "        for doc in res.get(\"hits\", {}):\n",
    "            doc_id = doc.get(\"_id\")\n",
    "            scores[doc_id] = score_mlm(es, clm, qterms, doc_id)\n",
    "\n",
    "        # write top 100 results to file\n",
    "        for doc_id, score in sorted(scores.items(), key=lambda x: x[1], reverse=True)[:100]:            \n",
    "            fout.write(qid + \",\" + doc_id + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
